{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = \"Lucia Seitz\"\n",
    "__copyright__ = \"Copyright 2017, AI Research, Data Technology Centre, Volkswagen Group\"\n",
    "__credits__ = [\"Lucia Seitz, Karolina Stosio\"]\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import misc\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import scipy as sc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models import Bernoulli, Normal\n",
    "from edward.util import Progbar\n",
    "from observations import mnist\n",
    "from scipy.misc import imsave\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(array, batch_size):\n",
    "    \"\"\"Generate batch with respect to array's first axis.\"\"\"\n",
    "    start = 0    # pointer to where we are in iteration\n",
    "    while True:\n",
    "        stop = start + batch_size\n",
    "        diff = stop - array.shape[0]\n",
    "        if diff <= 0:\n",
    "            batch = array[start:stop]\n",
    "            start += batch_size\n",
    "        else:\n",
    "            batch = np.concatenate((array[start:], array[:diff]))\n",
    "            start = diff\n",
    "        batch = batch.astype(np.float32) / 255.0    # normalize pixel intensities\n",
    "        batch = np.random.binomial(1, batch)    # binarize images\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def generative_network(z):\n",
    "    \"\"\"Generative network to parameterize generative model. It takes\n",
    "    latent variables as input and outputs the likelihood parameters.\n",
    "    logits = neural_network(z)\n",
    "    \"\"\"\n",
    "    with slim.arg_scope([slim.conv2d_transpose],\n",
    "                                            activation_fn=tf.nn.elu,\n",
    "                                            normalizer_fn=slim.batch_norm,\n",
    "                                            normalizer_params={'scale': True}):\n",
    "        print('generative')\n",
    "        print(z)\n",
    "        net = tf.reshape(z, [M, 1, 1, d])\n",
    "        print(net)\n",
    "        net = slim.conv2d_transpose(net, 128, 4, stride=4)\n",
    "        print(net)\n",
    "        net = slim.conv2d_transpose(net, 64, 5, stride=2)\n",
    "        print(net)\n",
    "        net = slim.conv2d_transpose(net, 32, 5, stride=2)\n",
    "        print(net)\n",
    "        net = slim.conv2d_transpose(net, 16, 5, stride=2)\n",
    "        print(net)\n",
    "        net = slim.conv2d_transpose(net, 8, 5, stride=4)\n",
    "        print(net)\n",
    "        net = slim.conv2d_transpose(net, 4, 5, stride=2, activation_fn=None)\n",
    "        print(net)\n",
    "        net = slim.flatten(net)\n",
    "        print(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "def inference_network(x):\n",
    "    \"\"\"Inference network to parameterize variational model. It takes\n",
    "    data as input and outputs the variational parameters.\n",
    "    loc, scale = neural_network(x)\n",
    "    \"\"\"\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                                            activation_fn=tf.nn.elu,\n",
    "                                            normalizer_fn=slim.batch_norm,\n",
    "                                            normalizer_params={'scale': True}):\n",
    "        print('inference')\n",
    "        print(x)\n",
    "        #net = tf.reshape(x, [M, 28, 28, 1])\n",
    "        net = tf.reshape(x, [M, 256, 256, 4])\n",
    "        print(net)\n",
    "        net = slim.conv2d(net, 8, 5, stride=2)\n",
    "        print(net)\n",
    "        net = slim.conv2d(net, 16, 5, stride=3)\n",
    "        print(net)\n",
    "        net = slim.conv2d(net, 32, 5, stride=3)\n",
    "        print(net)\n",
    "        net = slim.conv2d(net, 64, 5, stride=2)\n",
    "        print(net)\n",
    "        net = slim.conv2d(net, 128, 5, padding='VALID')\n",
    "        print(net)\n",
    "        net = slim.dropout(net, 0.9)\n",
    "        print(net)\n",
    "        net = slim.flatten(net)\n",
    "        print(net)\n",
    "        params = slim.fully_connected(net, d * 2, activation_fn=None)\n",
    "        print('params',net)\n",
    "\n",
    "    loc = params[:, :d]\n",
    "    scale = tf.nn.softplus(params[:, d:])\n",
    "    print('loc',loc)\n",
    "    print('scale',scale)\n",
    "    return loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PATH = '/home/karolina/Documents/VW/synthetic_data'\n",
    "# images = glob.glob(PATH+'/*/*.png')\n",
    "# images.sort()\n",
    "# train_data = np.array([misc.imresize(misc.imread(im),20) for im in images[:100]])\n",
    "# names = [im.split('/')[-2] for im in images]\n",
    "# n_set = list(set(names))\n",
    "# numbers = [[i]*names.count(n_set[i]) for i in range(len(n_set))]\n",
    "# img_x, img_y, img_chan = train_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed.set_seed(42)\n",
    "\n",
    "data_dir = \"/tmp/data\"\n",
    "out_dir = \"/tmp/out\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "ed.set_seed(42)\n",
    "M = 128    # batch size during training\n",
    "d = 10     # latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generative\n",
      "RandomVariable(\"Normal_2/\", shape=(128, 10), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(128, 1, 1, 10), dtype=float32)\n",
      "Tensor(\"Conv2d_transpose/Elu:0\", shape=(128, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"Conv2d_transpose_1/Elu:0\", shape=(128, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"Conv2d_transpose_2/Elu:0\", shape=(128, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"Conv2d_transpose_3/Elu:0\", shape=(128, 32, 32, 16), dtype=float32)\n",
      "Tensor(\"Conv2d_transpose_4/Elu:0\", shape=(128, 128, 128, 8), dtype=float32)\n",
      "Tensor(\"Conv2d_transpose_5/BatchNorm/batchnorm/add_1:0\", shape=(128, 256, 256, 4), dtype=float32)\n",
      "Tensor(\"Flatten/Reshape:0\", shape=(128, 262144), dtype=float32)\n",
      "inference\n",
      "Tensor(\"Cast:0\", shape=(128, 262144), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(128, 256, 256, 4), dtype=float32)\n",
      "Tensor(\"Conv/Elu:0\", shape=(128, 128, 128, 8), dtype=float32)\n",
      "Tensor(\"Conv_1/Elu:0\", shape=(128, 43, 43, 16), dtype=float32)\n",
      "Tensor(\"Conv_2/Elu:0\", shape=(128, 15, 15, 32), dtype=float32)\n",
      "Tensor(\"Conv_3/Elu:0\", shape=(128, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"Conv_4/Elu:0\", shape=(128, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"Dropout/dropout/mul:0\", shape=(128, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"Flatten_1/Reshape:0\", shape=(128, 2048), dtype=float32)\n",
      "params Tensor(\"Flatten_1/Reshape:0\", shape=(128, 2048), dtype=float32)\n",
      "loc Tensor(\"strided_slice:0\", shape=(128, 10), dtype=float32)\n",
      "scale Tensor(\"Softplus:0\", shape=(128, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# DATA. MNIST batches are fed at training time.\n",
    "(x_train, _), (x_test, _) = mnist(data_dir)\n",
    "x_train_generator = generator(x_train, M)\n",
    "#x_train_generator = generator(train_data, M)\n",
    "\n",
    "# MODEL\n",
    "z = Normal(loc=tf.zeros([M, d]), scale=tf.ones([M, d]))\n",
    "logits = generative_network(z)\n",
    "x = Bernoulli(logits=logits)\n",
    "\n",
    "# INFERENCE\n",
    "x_ph = tf.placeholder(tf.int32, [M, 256*256*4])\n",
    "#x_ph = tf.placeholder(tf.int32, [M, img_x, img_y, img_chan])\n",
    "loc, scale = inference_network(tf.cast(x_ph, tf.float32))\n",
    "qz = Normal(loc=loc, scale=scale)\n",
    "\n",
    "# Bind p(x, z) and q(z | x) to the same placeholder for x.\n",
    "data = {x: x_ph}\n",
    "inference = ed.KLqp({z: qz}, data)\n",
    "optimizer = tf.train.AdamOptimizer(0.01, epsilon=1.0)\n",
    "inference.initialize(optimizer=optimizer)\n",
    "\n",
    "hidden_rep = tf.sigmoid(logits)\n",
    "\n",
    "tf.global_variables_initializer().run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### TRAINING\n",
    "\n",
    "# n_epoch = 100\n",
    "# n_iter_per_epoch = x_train.shape[0] // M\n",
    "# for epoch in range(1, n_epoch + 1):\n",
    "#     print(\"Epoch: {0}\".format(epoch))\n",
    "#     avg_loss = 0.0\n",
    "\n",
    "#     pbar = Progbar(n_iter_per_epoch)\n",
    "#     for t in range(1, n_iter_per_epoch + 1):\n",
    "#         pbar.update(t)\n",
    "#         x_batch = next(x_train_generator)\n",
    "#         info_dict = inference.update(feed_dict={x_ph: x_batch})\n",
    "#         avg_loss += info_dict['loss']\n",
    "\n",
    "#     # Print a lower bound to the average marginal likelihood for an\n",
    "#     # image.\n",
    "#     avg_loss = avg_loss / n_iter_per_epoch\n",
    "#     avg_loss = avg_loss / M\n",
    "#     print(\"-log p(x) <= {:0.3f}\".format(avg_loss))\n",
    "\n",
    "#     # Visualize hidden representations.\n",
    "#     images = hidden_rep.eval()\n",
    "#     for m in range(M):\n",
    "#         imsave(os.path.join(out_dir, '%d.png') % m, images[m].reshape(28, 28))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
